{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01003240",
   "metadata": {},
   "source": [
    "### Document Preparation and Ingestion [MANDATORY STEPS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8804c292",
   "metadata": {},
   "source": [
    "#### Step 1: Loading and Pre-processing the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a535f7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "PDF_PATH = \"../data/AI Training Document.pdf\"\n",
    "text = \"\"\n",
    "reader = PdfReader(PDF_PATH)\n",
    "\n",
    "for page in reader.pages:\n",
    "    cleaned_text = \" \".join(page.extract_text().split())\n",
    "    text += cleaned_text\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6686811e",
   "metadata": {},
   "source": [
    "#### Step 2: Creating chunks and storing it in separate directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdba1982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7e1d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 300\n",
    "\n",
    "sentences = sent_tokenize(text)\n",
    "chunks = []\n",
    "current_sentence = \"\"\n",
    "\n",
    "for sentence in sentences:\n",
    "    if len(current_sentence) <= CHUNK_SIZE and (len(current_sentence) + len(sentence) <= CHUNK_SIZE):\n",
    "        current_sentence += sentence\n",
    "    else:\n",
    "        chunks.append(current_sentence)\n",
    "        current_sentence = \"\"\n",
    "\n",
    "cleaned_chunks = [chunk for chunk in chunks if len(chunk) > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63c94300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk 1 to: ../chunks\\chunk_001.txt\n",
      "Saved chunk 2 to: ../chunks\\chunk_002.txt\n",
      "Saved chunk 3 to: ../chunks\\chunk_003.txt\n",
      "Saved chunk 4 to: ../chunks\\chunk_004.txt\n",
      "Saved chunk 5 to: ../chunks\\chunk_005.txt\n",
      "Saved chunk 6 to: ../chunks\\chunk_006.txt\n",
      "Saved chunk 7 to: ../chunks\\chunk_007.txt\n",
      "Saved chunk 8 to: ../chunks\\chunk_008.txt\n",
      "Saved chunk 9 to: ../chunks\\chunk_009.txt\n",
      "Saved chunk 10 to: ../chunks\\chunk_010.txt\n",
      "Saved chunk 11 to: ../chunks\\chunk_011.txt\n",
      "Saved chunk 12 to: ../chunks\\chunk_012.txt\n",
      "Saved chunk 13 to: ../chunks\\chunk_013.txt\n",
      "Saved chunk 14 to: ../chunks\\chunk_014.txt\n",
      "Saved chunk 15 to: ../chunks\\chunk_015.txt\n",
      "Saved chunk 16 to: ../chunks\\chunk_016.txt\n",
      "Saved chunk 17 to: ../chunks\\chunk_017.txt\n",
      "Saved chunk 18 to: ../chunks\\chunk_018.txt\n",
      "Saved chunk 19 to: ../chunks\\chunk_019.txt\n",
      "Saved chunk 20 to: ../chunks\\chunk_020.txt\n",
      "Saved chunk 21 to: ../chunks\\chunk_021.txt\n",
      "Saved chunk 22 to: ../chunks\\chunk_022.txt\n",
      "Saved chunk 23 to: ../chunks\\chunk_023.txt\n",
      "Saved chunk 24 to: ../chunks\\chunk_024.txt\n",
      "Saved chunk 25 to: ../chunks\\chunk_025.txt\n",
      "Saved chunk 26 to: ../chunks\\chunk_026.txt\n",
      "Saved chunk 27 to: ../chunks\\chunk_027.txt\n",
      "Saved chunk 28 to: ../chunks\\chunk_028.txt\n",
      "Saved chunk 29 to: ../chunks\\chunk_029.txt\n",
      "Saved chunk 30 to: ../chunks\\chunk_030.txt\n",
      "Saved chunk 31 to: ../chunks\\chunk_031.txt\n",
      "Saved chunk 32 to: ../chunks\\chunk_032.txt\n",
      "Saved chunk 33 to: ../chunks\\chunk_033.txt\n",
      "Saved chunk 34 to: ../chunks\\chunk_034.txt\n",
      "Saved chunk 35 to: ../chunks\\chunk_035.txt\n",
      "Saved chunk 36 to: ../chunks\\chunk_036.txt\n",
      "Saved chunk 37 to: ../chunks\\chunk_037.txt\n",
      "Saved chunk 38 to: ../chunks\\chunk_038.txt\n",
      "Saved chunk 39 to: ../chunks\\chunk_039.txt\n",
      "Saved chunk 40 to: ../chunks\\chunk_040.txt\n",
      "Saved chunk 41 to: ../chunks\\chunk_041.txt\n",
      "Saved chunk 42 to: ../chunks\\chunk_042.txt\n",
      "Saved chunk 43 to: ../chunks\\chunk_043.txt\n",
      "Saved chunk 44 to: ../chunks\\chunk_044.txt\n",
      "Saved chunk 45 to: ../chunks\\chunk_045.txt\n",
      "Saved chunk 46 to: ../chunks\\chunk_046.txt\n",
      "Saved chunk 47 to: ../chunks\\chunk_047.txt\n",
      "Saved chunk 48 to: ../chunks\\chunk_048.txt\n",
      "Saved chunk 49 to: ../chunks\\chunk_049.txt\n",
      "Saved chunk 50 to: ../chunks\\chunk_050.txt\n",
      "Saved chunk 51 to: ../chunks\\chunk_051.txt\n",
      "Saved chunk 52 to: ../chunks\\chunk_052.txt\n",
      "Saved chunk 53 to: ../chunks\\chunk_053.txt\n",
      "Saved chunk 54 to: ../chunks\\chunk_054.txt\n",
      "Saved chunk 55 to: ../chunks\\chunk_055.txt\n",
      "Saved chunk 56 to: ../chunks\\chunk_056.txt\n",
      "Saved chunk 57 to: ../chunks\\chunk_057.txt\n",
      "Saved chunk 58 to: ../chunks\\chunk_058.txt\n",
      "Saved chunk 59 to: ../chunks\\chunk_059.txt\n",
      "Saved chunk 60 to: ../chunks\\chunk_060.txt\n",
      "Saved chunk 61 to: ../chunks\\chunk_061.txt\n",
      "Saved chunk 62 to: ../chunks\\chunk_062.txt\n",
      "Saved chunk 63 to: ../chunks\\chunk_063.txt\n",
      "Saved chunk 64 to: ../chunks\\chunk_064.txt\n",
      "Saved chunk 65 to: ../chunks\\chunk_065.txt\n",
      "Saved chunk 66 to: ../chunks\\chunk_066.txt\n",
      "Saved chunk 67 to: ../chunks\\chunk_067.txt\n",
      "Saved chunk 68 to: ../chunks\\chunk_068.txt\n",
      "Saved chunk 69 to: ../chunks\\chunk_069.txt\n",
      "Saved chunk 70 to: ../chunks\\chunk_070.txt\n",
      "Saved chunk 71 to: ../chunks\\chunk_071.txt\n",
      "Saved chunk 72 to: ../chunks\\chunk_072.txt\n",
      "Saved chunk 73 to: ../chunks\\chunk_073.txt\n",
      "Saved chunk 74 to: ../chunks\\chunk_074.txt\n",
      "Saved chunk 75 to: ../chunks\\chunk_075.txt\n",
      "Saved chunk 76 to: ../chunks\\chunk_076.txt\n",
      "Saved chunk 77 to: ../chunks\\chunk_077.txt\n",
      "Saved chunk 78 to: ../chunks\\chunk_078.txt\n",
      "Saved chunk 79 to: ../chunks\\chunk_079.txt\n",
      "Saved chunk 80 to: ../chunks\\chunk_080.txt\n",
      "Saved chunk 81 to: ../chunks\\chunk_081.txt\n",
      "Saved chunk 82 to: ../chunks\\chunk_082.txt\n",
      "Saved chunk 83 to: ../chunks\\chunk_083.txt\n",
      "Saved chunk 84 to: ../chunks\\chunk_084.txt\n",
      "Saved chunk 85 to: ../chunks\\chunk_085.txt\n",
      "Saved chunk 86 to: ../chunks\\chunk_086.txt\n",
      "Saved chunk 87 to: ../chunks\\chunk_087.txt\n",
      "Saved chunk 88 to: ../chunks\\chunk_088.txt\n",
      "Saved chunk 89 to: ../chunks\\chunk_089.txt\n",
      "Saved chunk 90 to: ../chunks\\chunk_090.txt\n",
      "Saved chunk 91 to: ../chunks\\chunk_091.txt\n",
      "Saved chunk 92 to: ../chunks\\chunk_092.txt\n",
      "Saved chunk 93 to: ../chunks\\chunk_093.txt\n",
      "Saved chunk 94 to: ../chunks\\chunk_094.txt\n",
      "Saved chunk 95 to: ../chunks\\chunk_095.txt\n",
      "Saved chunk 96 to: ../chunks\\chunk_096.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "output_dir = '../chunks'\n",
    "\n",
    "for i, chunk in enumerate(cleaned_chunks):\n",
    "    chunk_filename = os.path.join(output_dir, f\"chunk_{i+1:03d}.txt\")\n",
    "    try:\n",
    "        with open(chunk_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(chunk)\n",
    "        print(f\"Saved chunk {i+1} to: {chunk_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving chunk {i+1} to {chunk_filename}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cade3bf6",
   "metadata": {},
   "source": [
    "#### Step 3: Creating Embeddings for our chunks and then storing it in a vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f2d20a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "DB_PATH = '../vectordb'\n",
    "\n",
    "documents = [Document(page_content=chunk) for chunk in cleaned_chunks]\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vector_db = FAISS.from_documents(documents, embeddings)\n",
    "vector_db.save_local(DB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69c4da57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '1477c90d-6876-47fa-9a87-b97a755e6b10',\n",
       " 1: '4fd4edd7-57da-4e5d-a955-70cdb6b8c17f',\n",
       " 2: 'c1f6fb4a-6a32-4800-96a4-ed717c23fb47',\n",
       " 3: 'ba585523-e65d-4c09-90bd-924d981ce9cd',\n",
       " 4: '10112fdc-20fc-4add-85c8-d8943b26b4ff',\n",
       " 5: 'ffec3d49-f45a-4fad-9e4c-4683b392cb7c',\n",
       " 6: 'cf9bd4bf-e699-45c7-a186-3cdcbad8944a',\n",
       " 7: '0b1322ae-0955-4dca-bd70-a435fae56f47',\n",
       " 8: 'a2a6382f-0a0c-4926-94bd-2740177e913d',\n",
       " 9: 'e9033aec-93fa-4c01-970f-92acab53d2dc',\n",
       " 10: '1f48254e-7bfb-475d-9dea-c0fb18912d20',\n",
       " 11: 'cea5bf18-c224-491c-b20e-7cb9bb02a9bc',\n",
       " 12: '3f60ffb2-d3f7-4b65-8378-c99549df48e1',\n",
       " 13: '5de63523-803e-4f07-b5a9-c4e3852dd636',\n",
       " 14: '8e187830-6bb8-4f84-9e5a-3478ccefb3bb',\n",
       " 15: 'c79f7c64-008d-4444-a47d-57c9d9123ba1',\n",
       " 16: 'da20e317-037f-4d10-a914-dbcef2003fd1',\n",
       " 17: '7d571427-7002-4c4e-aa42-20a9df690cca',\n",
       " 18: '166671f9-df13-4cc1-bbb7-899c49915129',\n",
       " 19: '8eff7352-5461-4d77-84d4-596b6ceea39c',\n",
       " 20: 'fae9ac78-c57c-4b98-990f-387f9fbb47c1',\n",
       " 21: '0056fb17-43c8-4228-93b3-a58df7a484c4',\n",
       " 22: 'a75dc03c-85ab-4988-a0a0-b98dd229bfc1',\n",
       " 23: '8c941068-4f8b-471e-acfc-6e2b27b5ff43',\n",
       " 24: 'b9bcaa20-42f6-4755-8670-dd71f5c52c75',\n",
       " 25: '611fb06c-d606-4945-8689-632d73626650',\n",
       " 26: 'b1ed2123-db2a-4fe0-a3cb-ff816ebc4191',\n",
       " 27: '53275665-a7ee-45f4-a199-cdcafeafd62e',\n",
       " 28: '03603e47-ca93-48bd-8469-46cf4a2d6969',\n",
       " 29: '974d1729-a765-4570-8a2e-ee33d5a4c5b0',\n",
       " 30: 'c4e5bd57-08e9-4df2-8e42-1cf51a12821c',\n",
       " 31: '630d1fff-050d-45c0-afb0-644cff5ae2c7',\n",
       " 32: 'cd4660db-1dc7-42b9-8dbb-bee3855a27f9',\n",
       " 33: 'de957cc0-8d55-4f79-b6e8-ecb6fefb1fe8',\n",
       " 34: '6675be29-9d07-4892-b057-b5163efb0fb7',\n",
       " 35: 'eff9d741-8cce-46d9-9658-133a856b37f1',\n",
       " 36: '21563672-f18d-48fb-80f8-9ee7e8095f9b',\n",
       " 37: 'e9f903b3-03b9-4106-b9f2-f155e73474a7',\n",
       " 38: '7ef542e9-805f-4620-96ca-9c7da67c9d05',\n",
       " 39: 'ca1990f9-8e01-4e3b-bfc4-75c931623889',\n",
       " 40: '910a2bd5-e8dc-44b6-9910-dffe35900d15',\n",
       " 41: '755bb643-e379-468b-891d-98da6ca57cd7',\n",
       " 42: 'b357ea1f-ed25-45e3-9ecc-6a39d3a140a0',\n",
       " 43: 'ff5f0dbc-0e86-4c16-ae47-46cf8267f635',\n",
       " 44: 'ed6aa85c-3281-4cb6-b8b6-ab4779fe1e64',\n",
       " 45: '5d5ad737-8e76-48ef-9292-0cc9710d1a3b',\n",
       " 46: '8d787e82-d273-4da3-bdf5-40be364fa81f',\n",
       " 47: '701f22f2-53c7-414c-96e4-9d6888fe9e3c',\n",
       " 48: '25a37e95-d717-4124-a985-a928c5a36fb9',\n",
       " 49: 'f6a4bd96-eb8f-4f8e-aff2-2cef0c84bcfc',\n",
       " 50: '8fb16eed-d135-43d8-9e01-fa9ed9a6e540',\n",
       " 51: '784a1210-cd94-476d-9cf9-329ad4d415e4',\n",
       " 52: 'f42f0543-ce5f-4691-9aff-626e64c3be65',\n",
       " 53: '14025408-15a7-4616-ae36-feba9c5cabd5',\n",
       " 54: 'd798b92c-b583-40c3-be02-d0f772d43f96',\n",
       " 55: '38e64da8-0cee-4a05-be06-b68f5d4945fe',\n",
       " 56: '6ec85a36-bd70-4720-8e10-1e4c614d5834',\n",
       " 57: '0e243fe2-067f-4e29-907e-f1060c581660',\n",
       " 58: '5cd5bb38-e2fb-4afc-b8c2-67802f8d289f',\n",
       " 59: 'ae5ecc2d-cd99-4625-a1bc-12422604196d',\n",
       " 60: 'c6a09b04-5745-4286-980a-d630cf23eab8',\n",
       " 61: 'da042611-887e-4ddb-988a-30f9ff8817fc',\n",
       " 62: '1ad11a0a-78ba-4f53-8d89-ca560a7f7e94',\n",
       " 63: '8e89e2dc-9701-49e3-a3ea-0791c997c33f',\n",
       " 64: 'cfe12603-4187-474a-b5c2-9c14efc5e527',\n",
       " 65: '8730d8a0-8742-412a-93fb-81687c625419',\n",
       " 66: 'e6126ffd-bf19-47d6-88b6-01c0a536f0d5',\n",
       " 67: '3f56deb6-ca69-4a04-9d98-5f586aa88e92',\n",
       " 68: '7905cd1d-bd38-48bc-b90a-923451c5e16b',\n",
       " 69: '39c649de-5054-43c4-9283-7866fa8f2aee',\n",
       " 70: '079f9205-9653-49cb-8288-20d573c22787',\n",
       " 71: 'f17d3eaa-8f83-48f2-9410-b3893911b54f',\n",
       " 72: '93ce5b7d-d33f-4500-9074-329925d79e96',\n",
       " 73: '1ff31a94-8c14-4b00-bafb-016e971fcb93',\n",
       " 74: '23ec0443-3b52-4747-93b6-d0c9b73f350f',\n",
       " 75: 'e5e825f0-2a00-43ac-be94-565350b296ee',\n",
       " 76: '3457d8a5-ed0d-4972-b2d1-a1b722a8233d',\n",
       " 77: '819fe981-7131-4679-b620-052a94e3581c',\n",
       " 78: '125f4624-d386-4d16-bbde-c3feec8968a7',\n",
       " 79: 'd390e1e3-d389-4f25-b2d3-75560463603d',\n",
       " 80: '41e3f49c-b2b7-4898-b139-51492de1cb5b',\n",
       " 81: '390f77d8-7dc0-47bd-a67e-4f41364fac60',\n",
       " 82: 'f67cadbc-c824-4d4a-962d-bf03971c84c7',\n",
       " 83: '75ea004c-bc0e-4799-9c09-30dd49fe683b',\n",
       " 84: '920e1436-345c-41fe-8371-47399dbbff6f',\n",
       " 85: '5a25cce1-4117-438a-823d-88344582d338',\n",
       " 86: '55ae57c9-307c-4a88-b17f-1d463fe526a9',\n",
       " 87: '7664a998-0185-44fa-adf3-863cf59af37b',\n",
       " 88: '18bfa10d-ac20-47d4-a075-9ef13e3b42bf',\n",
       " 89: '915f890c-b84c-4a6c-8594-c96eb823b4ad',\n",
       " 90: '90d66d03-5455-4e74-94d4-0e330b6cd115',\n",
       " 91: '8122f07f-bc11-4389-995f-7cb0ddccf264',\n",
       " 92: 'f9bec029-16a7-4494-b277-8ba5d2c38514',\n",
       " 93: '7e2ee7d1-1de7-4e35-8cef-bf7c066d6dcc',\n",
       " 94: 'c9d16171-7625-40f6-9d6c-1c5bd4bc7bd5',\n",
       " 95: 'e2bf284f-5435-4fa4-a8db-27ac95707b4e'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db.index_to_docstore_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f78845ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='5de63523-803e-4f07-b5a9-c4e3852dd636', metadata={}, page_content='Neither the accuracy of vehicle information provided on eBay.com, nor the availability, quality, or safety of vehicles is guaranteed by eBay.Furthermore, neither the financing of or insurance relevant to vehicles is controlled or guaranteed b y eBay.')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db.get_by_ids(['5de63523-803e-4f07-b5a9-c4e3852dd636'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc86705",
   "metadata": {},
   "source": [
    "### Fine-Tuning and Evaluation [OPTIONAL]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23d22de",
   "metadata": {},
   "source": [
    "#### Checking if the retriever is working or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d9816ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001A4DEA5C560>, search_kwargs={'k': 4})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_db.as_retriever(search_type='similarity', search_kwargs={\"k\": 4})\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "606e8077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='c79f7c64-008d-4444-a47d-57c9d9123ba1', metadata={}, page_content='6.Fees and Taxes We charge sellers for the use of our Services.In some cases, where buyers receive supplemental Services such as authentication or storage Services for items in certain categories, we may also charge those buyers for such supplemental Services.'),\n",
       " Document(id='079f9205-9653-49cb-8288-20d573c22787', metadata={}, page_content='The NAM Rules are cur rently available at https://www.namadr.com/resources/rules -fees-forms/ .'),\n",
       " Document(id='da20e317-037f-4d10-a914-dbcef2003fd1', metadata={}, page_content='You as a seller must have a payment method on file when using our selling Services and pay all fees and applicable taxes associated with your use of our Services by the payment due date.'),\n",
       " Document(id='a2a6382f-0a0c-4926-94bd-2740177e913d', metadata={}, page_content='Also, as provided below in the Fees and Taxes section, if we believe you are violating our policy on buying or selling outside of eBay , you may be charged final value fees.We may cancel unconfirmed accounts or accounts that have been inactive for a substantial period of time.')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What about fees?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c82fb0a",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c343da69",
   "metadata": {},
   "source": [
    "Here we have used ollama to run Mistral 7b instruct model locally. In order to use this first we have to download and install ollama, then pull mistral 7b instruct model using ollama. Both should be properly done in order to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84794ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(\n",
    "    model=\"mistral:7b-instruct\",\n",
    "    temperature=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58d47b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(\"hii there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08d9c207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Hello! How can I help you today? Is there something specific you would like to know or discuss? I'm here to assist with any questions you might have.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a65c0c",
   "metadata": {},
   "source": [
    "#### Designing a basic template and defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32774e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a helpful and honest assistant. Use the following context to answer the user's question. \n",
    "Only answer based on the context provided. If the answer is not found in the context, say \"I don't know based on the given information.\"\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "731a2f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=['context', 'question']\n",
    ")\n",
    "\n",
    "llm = OllamaLLM(model=\"mistral:7b-instruct\", temperature=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9712f6",
   "metadata": {},
   "source": [
    "##### **Type 1:** Manually running each steps i.e not chaining it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c4a7741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What kind of privacy policies are written here?\"\n",
    "retrieved_docs = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "91af4c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1add0935",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = prompt.invoke({\"context\": context_text, \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a7717000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the provided context, there is no explicit mention of privacy policies in this User Agreement. The text primarily discusses terms related to content ownership, warranties, and liability for such content, as well as policy enforcement and disclaimers regarding the Services' operation. However, without more information about the broader document or platform from which these excerpts are taken, it is impossible to definitively state whether privacy policies are included elsewhere in the agreement."
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Based on the provided context, there is no explicit mention of privacy policies in this User Agreement. The text primarily discusses terms related to content ownership, warranties, and liability for such content, as well as policy enforcement and disclaimers regarding the Services' operation. However, without more information about the broader document or platform from which these excerpts are taken, it is impossible to definitively state whether privacy policies are included elsewhere in the agreement.\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(final_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ba99c7",
   "metadata": {},
   "source": [
    "##### **Type 2:** Chaining all the steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ae1631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf2b52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The provided context suggests that the platform enforces its policies flexibly, taking into account both the user's performance history and specific circumstances. However, it does not specify explicit details about how policies are enforced or provide a comprehensive list of policies. For more detailed information about the policies, you should refer to the platform's terms of service or contact their customer support."
     ]
    }
   ],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "qa_chain = (\n",
    "    {\n",
    "        \"context\": vector_db.as_retriever() | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    } | prompt | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "res = qa_chain.stream(\"what about the policies?\")\n",
    "for r in res:\n",
    "    print(r, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacb28b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
